{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\areeba khan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_names = [\"lusc\"]\n",
    "methods = [\"mds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_download = {}\n",
    "# for cancer in cancer_names:\n",
    "#     for method in methods:\n",
    "#         for n in [50, 75, 100, 150]:\n",
    "#             with open (f\"C:/Users/areeba khan/Documents/UdS/Master Thesis/gene_sets/cmap_query_sets/all/equal_sets/{method}/top_{n}_upregulated_genes.txt\") as file:\n",
    "#                 file_list = file.read().splitlines()\n",
    "\n",
    "#             with open(f\"C:/Users/areeba khan/Documents/UdS/Master Thesis/gene_sets/cmap_query_sets/all/equal_sets/{method}/top_{n}_downregulated_genes.txt\") as f:\n",
    "#                 down_f = f.read().splitlines()\n",
    "\n",
    "#             if len(down_f) > 10 and len(file_list) > 10:\n",
    "#                 file_list = 'TAG\\\\t\\\\t' + ('\\\\t'.join([str(x) for x in file_list]))\n",
    "#                 down_f = 'TAG\\\\t\\\\t' + ('\\\\t'.join([str(x) for x in down_f]))\n",
    "\n",
    "#                 headers = {\n",
    "#                     'Content-Type': 'application/json',\n",
    "#                     'Accept': 'application/json',\n",
    "#                     'user_key': '2f844a47b5bad670768300263f923a92',\n",
    "#                 }\n",
    "#                 new_n = n + n\n",
    "#                 query_name = cancer + \"_\" + str(new_n) + \"_variable_\" + method\n",
    "#                 data = f'''\n",
    "#                 {{\n",
    "#                     \"tool_id\": \"sig_gutc_tool\",\n",
    "#                     \"data_type\": \"L1000\",\n",
    "#                     \"name\": \"{query_name}\",\n",
    "#                     \"uptag-cmapfile\": \"{file_list}\",\n",
    "#                     \"dntag-cmapfile\": \"{down_f}\",\n",
    "#                     \"dataset\": \"Touchstone\",\n",
    "#                     \"ignoreWarnings\": true\n",
    "#                 }}\n",
    "#                 '''\n",
    "#                 response = requests.post('https://api.clue.io/api/jobs', headers=headers, data=data)\n",
    "#                 if response.status_code == 200:\n",
    "#                     response_dict = response.json()\n",
    "#                     dict_download[query_name] = response['result']['job_id']\n",
    "#                 else:\n",
    "#                     print(f\"Failed to submit job {query_name}. Status Code: {response.status_code}\")\n",
    "#                     continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_queries(cancer_names, methods):\n",
    "    dict_download = {}\n",
    "    dict_errors = {}\n",
    "\n",
    "    batch_size = 10\n",
    "    query_count = 0\n",
    "\n",
    "    for cancer in cancer_names:\n",
    "        for method in methods:\n",
    "            for n in [50, 75, 100, 150]:\n",
    "                new_n = n + n\n",
    "                query_name = cancer + \"_\" + str(new_n) + \"_equal_\" + method\n",
    "                try:\n",
    "                    with open(f\"C:/Users/areeba khan/Documents/UdS/Master Thesis/gene_sets/cmap_query_sets/{cancer}/equal_sets/{method}/top_{n}_upregulated_genes.txt\") as file:\n",
    "                        file_list = file.read().splitlines()\n",
    "\n",
    "                    with open(f\"C:/Users/areeba khan/Documents/UdS/Master Thesis/gene_sets/cmap_query_sets/{cancer}/equal_sets/{method}/top_{n}_downregulated_genes.txt\") as f:\n",
    "                        down_f = f.read().splitlines()\n",
    "\n",
    "                    if len(down_f) > 10 and len(file_list) > 10:\n",
    "                        file_list = 'TAG\\\\t\\\\t' + ('\\\\t'.join([str(x) for x in file_list]))\n",
    "                        down_f = 'TAG\\\\t\\\\t' + ('\\\\t'.join([str(x) for x in down_f]))\n",
    "\n",
    "                        headers = {\n",
    "                            'Content-Type': 'application/json',\n",
    "                            'Accept': 'application/json',\n",
    "                            'user_key': '2f844a47b5bad670768300263f923a92',\n",
    "                        }\n",
    "\n",
    "                        \n",
    "                        data = f'''\n",
    "                        {{\n",
    "                            \"tool_id\": \"sig_gutc_tool\",\n",
    "                            \"data_type\": \"L1000\",\n",
    "                            \"name\": \"{query_name}\",\n",
    "                            \"uptag-cmapfile\": \"{file_list}\",\n",
    "                            \"dntag-cmapfile\": \"{down_f}\",\n",
    "                            \"dataset\": \"Touchstone\",\n",
    "                            \"ignoreWarnings\": true\n",
    "                        }}\n",
    "                        '''\n",
    "\n",
    "                        response = requests.post('https://api.clue.io/api/jobs', headers=headers, data=data)\n",
    "\n",
    "                        if response.status_code == 200:\n",
    "                            response_dict = response.json()\n",
    "                            dict_download[query_name] = response_dict['result']['job_id']\n",
    "                        else:\n",
    "                            dict_errors[query_name] = f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "                        query_count += 1\n",
    "\n",
    "                        if query_count % batch_size == 0:\n",
    "                            print(f\"Waiting for 30 minutes after submitting {query_count} queries...\")\n",
    "                            time.sleep(1800)  \n",
    "                            \n",
    "                except Exception as e:\n",
    "                    dict_errors[query_name] = str(e)\n",
    "\n",
    "    # Save the results to CSV files\n",
    "    save_to_csv(dict_download, f'C:/Users/areeba khan/Documents/UdS/Master Thesis/{cancer}_download_jobs.csv', ['query_name', 'job_id'])\n",
    "    save_to_csv(dict_errors, f'C:/Users/areeba khan/Documents/UdS/Master Thesis/{cancer}_error_jobs.csv', ['query_name', 'error'])\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_dict, file_name, fieldnames):\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for key, value in data_dict.items():\n",
    "            writer.writerow({fieldnames[0]: key, fieldnames[1]: value})\n",
    "\n",
    "\n",
    "submit_queries(cancer_names, methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (f\"C:/Users/areeba khan/Documents/UdS/Master Thesis/gene_sets/cmap_query_sets/lusc/variable_sets/vertex/top_200_upregulated_genes.txt\") as file:\n",
    "                file_list = file.read().splitlines()\n",
    "\n",
    "with open(f\"C:/Users/areeba khan/Documents/UdS/Master Thesis/gene_sets/cmap_query_sets/lusc/variable_sets/vertex/top_200_downregulated_genes.txt\") as f:\n",
    "    down_f = f.read().splitlines()\n",
    "\n",
    "if len(down_f) > 10 and len(file_list) > 10:\n",
    "    file_list = 'TAG\\\\t\\\\t' + ('\\\\t'.join([str(x) for x in file_list]))\n",
    "    down_f = 'TAG\\\\t\\\\t' + ('\\\\t'.join([str(x) for x in down_f]))\n",
    "\n",
    "# Headers\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "    'user_key': '2f844a47b5bad670768300263f923a92',\n",
    "}\n",
    "\n",
    "\n",
    "data = f'''\n",
    "{{\n",
    "    \"tool_id\": \"sig_gutc_tool\",\n",
    "    \"data_type\": \"L1000\",\n",
    "    \"name\": \"lusc_200_variable_vertex\",\n",
    "    \"uptag-cmapfile\": \"{file_list}\",\n",
    "    \"dntag-cmapfile\": \"{down_f}\",\n",
    "    \"dataset\": \"Touchstone\",\n",
    "    \"ignoreWarnings\": true\n",
    "}}\n",
    "'''\n",
    "\n",
    "response = requests.post('https://api.clue.io/api/jobs', headers=headers, data=data)\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers_get = {\n",
    "    'Accept': 'application/json',\n",
    "    'user_key': '2f844a47b5bad670768300263f923a92',\n",
    "}\n",
    "\n",
    "response_id = requests.get('http://api.clue.io/api/jobs/findByJobId/671613cfc072eb001379454d', headers=headers_get)\n",
    "print(response_id.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = response_id.json()\n",
    "\n",
    "download_url = di['download_url']\n",
    "\n",
    "# Ensure the URL starts with \"https:\"\n",
    "if download_url.startswith(\"//\"):\n",
    "    download_url = \"https:\" + download_url\n",
    "\n",
    "# Local filename to save the downloaded file\n",
    "local_filename = \"C:/Users/areeba khan/Documents/UdS/Master Thesis/CMAP_Output/lusc/variable_set/vertex/lusc_200_vertex.tar.gz\"\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(download_url, stream=True)\n",
    "\n",
    "# Save the file locally\n",
    "with open(local_filename, 'wb') as file:\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        if chunk:  # Only write if the chunk is not empty\n",
    "            file.write(chunk)\n",
    "\n",
    "print(f\"File downloaded and saved as {local_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def download_files(job_ids_csv, output_directory, method_names):\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'user_key': '2f844a47b5bad670768300263f923a92',  # Replace with your actual API key\n",
    "    }\n",
    "\n",
    "    # Ensure the base output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Read the job IDs and names from the CSV file\n",
    "    with open(job_ids_csv, mode='r') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            query_name = row['query_name']  # Name of the query\n",
    "            job_id = row['job_id']  # Job ID\n",
    "            response_id = requests.get(f'http://api.clue.io/api/jobs/findByJobId/{job_id}', headers=headers)\n",
    "            di = response_id.json()\n",
    "\n",
    "            download_url = di['download_url']\n",
    "\n",
    "            if download_url.startswith(\"//\"):\n",
    "                download_url = \"https:\" + download_url\n",
    "\n",
    "            subfolder = determine_subfolder(query_name, method_names)\n",
    "            save_path = os.path.join(output_directory, subfolder)\n",
    "\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "\n",
    "            print(f\"Fetching job result for: {query_name} (Job ID: {job_id})\")\n",
    "            # job_status_url = f\"https://api.clue.io/api/jobs/{job_id}\"\n",
    "\n",
    "            # Get job details (including the download URL)\n",
    "            response = requests.get(download_url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                # job_data = response.json()\n",
    "                # download_url = job_data.get('download_url')\n",
    "\n",
    "                # if download_url:\n",
    "                #     # Ensure the URL is formatted properly\n",
    "                #     if download_url.startswith(\"//\"):\n",
    "                #         download_url = \"https:\" + download_url\n",
    "\n",
    "                    # Set the local filename\n",
    "                local_filename = os.path.join(save_path, f\"{query_name}.tar.gz\")\n",
    "\n",
    "                # Download and save the file\n",
    "                print(f\"Downloading {query_name} to {local_filename}...\")\n",
    "                download_file(download_url, local_filename)\n",
    "                print(f\"File saved as: {local_filename}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"Failed to fetch job details for Job ID: {job_id}. Status Code: {response.status_code}\")\n",
    "\n",
    "def determine_subfolder(query_name, method_names):\n",
    "    if \"variable\" in query_name.lower():\n",
    "        for method in method_names:\n",
    "            if method.lower() in query_name.lower():\n",
    "                return os.path.join(\"variable_set\", method)\n",
    "        return \"equal_set\"\n",
    "    for method in method_names:\n",
    "        if method.lower() in query_name.lower():\n",
    "            return method\n",
    "    return \"others\"\n",
    "\n",
    "def download_file(url, local_filename):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(local_filename, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file {local_filename}: {e}\")\n",
    "\n",
    "job_ids_csv = \"C:/Users/areeba khan/Documents/UdS/Master Thesis/prad_download_jobs.csv\"\n",
    "output_directory = \"C:/Users/areeba khan/Documents/UdS/Master Thesis/CMAP_Output/all_prad/\"\n",
    "method_names = [\"degs\", \"bfs\"]\n",
    "\n",
    "download_files(job_ids_csv, output_directory, method_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
